{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Compilers Morteza Zakeri \u2020 \u2020 Ph.D. Student, Iran University of Science and Technology, Tehran, Iran (m-zakeri@live.com). Version 0.1.2 (29 March 2021) \u251c Download [PDF] version Abstract\u2014 O ur IUST-Compiler Course is now more practical than ever. This repository contains several code snippets that I developed to teach the ANTLR compiler generator at Iran University of Science and Technology (UST). Grammars have been written in ANTRL v4 format. For each grammar, the source code of Lexer and Parser is available in Python 3.x. The repository is assumed to be updated regularly. It would be appreciated if you use this repository by forking it. For any question please contact me m-zakeri@live.com Introduction The course is intended to teach the students the basic techniques that underlie the practice of Compiler Construction. The course will introduce the theory and tools that can be standardly employed to perform syntax-directed translation of a high-level programming language into executable code. These techniques can also be employed in broader areas of application, whenever we need a syntax-directed analysis of symbolic expressions and languages and their translation into a lower-level description. They have multiple uses for man-machine interaction, including verification and program analysis. Objectives To learn overall compilers architecture, To learn various parsing methods and techniques, To learn low-level code generation and optimization, To learn an intellectual paradigm in system programming and testing. Motivations Compiler construction is a microcosm of computer science! You dive into the heart of the system when you are building a compiler. Examples The following outputs could be generated by code snippets in this repository. Three addresses codes Figure 1 shows how a single pass compiler can generate three address code for assignment statements with minimum numbers of temporary variable, started with T : Fig 1: Examples of three addresses codes generated by ANTLR for AssignmentStatement grammar. Abstract Syntax Tree (AST) Figure 2 demonstrates how a single pass compiler can generate abstract syntax three (AST) for assignment statements. Fig 2: Examples of abstract syntax tree (AST) generated by ANTLR for AssignmentStatement grammar. Structure The following describes the structure of the repository: grammars gram1 : ANTRL hello world grammar. Expr1 : Simple grammar for handling mathematical expressions without any attribute and action. Expr2 : Simple attributed grammar for handling mathematical expressions with code() attribute. Expr3 : Currently, it is the same Expr2 grammar. AssignmentStatement1.g4 : The grammar to handle multiple assignment statements and mathematical expressions in programming languages like Pascal and C/C++ . AssignmentStatement2.g4 : It is the same AssignmentStatement1.g4 grammar plus attributes for code and type of rules. AssignmentStatement3.g4 : The grammar to handle multiple assignment statements and mathematical expressions in programming languages like Pascal and C/C++ . It provides semantic rules to perform type checking and semantic routines to generate intermediate representation. AssignmentStatement4.g4 : The grammar to handle multiple assignment statements and mathematical expressions in programming languages like Pascal and C/C++ . It provides semantic rules to perform type checking and semantic routines to generate intermediate representation. It has been implemented to generate intermediate representation (three addresses codes) with minimum number of \"temp\" variables. CPP14_v2 : ANTLR grammar for C++14 forked from the official ANTRL website. Some bugs have been fixed and also the rule identifiers have been added to the grammar rules. EMail.g4 : Lexical grammar to validate email addresses. EMail2.g4 : Lexical grammar to validate email addresses, fixing bugs in EMail.g4 language_apps The language_apps package currently contains Lexer and Parser codes for each grammar in directory grammars , with a main driver script to demonstrate the type checking and intermediate code generation based on semantic rules and semantic routines . terminal_batch_scripts The termina_batch_script directory contains several batch script to run ANTLR in terminal (Windows) to generate target code in JAVA language. The code snippets in this directory belong to my first experiences with ANTLR. Read more IUST compiler course official webpage ANTLR slides: PART 1: Introduction ANTLR slides: PART 2: Getting started in Java ANTLR slides: PART 3: Getting started in C#","title":"Home"},{"location":"#compilers","text":"Morteza Zakeri \u2020 \u2020 Ph.D. Student, Iran University of Science and Technology, Tehran, Iran (m-zakeri@live.com). Version 0.1.2 (29 March 2021) \u251c Download [PDF] version Abstract\u2014 O ur IUST-Compiler Course is now more practical than ever. This repository contains several code snippets that I developed to teach the ANTLR compiler generator at Iran University of Science and Technology (UST). Grammars have been written in ANTRL v4 format. For each grammar, the source code of Lexer and Parser is available in Python 3.x. The repository is assumed to be updated regularly. It would be appreciated if you use this repository by forking it. For any question please contact me m-zakeri@live.com","title":"Compilers"},{"location":"#introduction","text":"The course is intended to teach the students the basic techniques that underlie the practice of Compiler Construction. The course will introduce the theory and tools that can be standardly employed to perform syntax-directed translation of a high-level programming language into executable code. These techniques can also be employed in broader areas of application, whenever we need a syntax-directed analysis of symbolic expressions and languages and their translation into a lower-level description. They have multiple uses for man-machine interaction, including verification and program analysis.","title":"Introduction"},{"location":"#objectives","text":"To learn overall compilers architecture, To learn various parsing methods and techniques, To learn low-level code generation and optimization, To learn an intellectual paradigm in system programming and testing.","title":"Objectives"},{"location":"#motivations","text":"Compiler construction is a microcosm of computer science! You dive into the heart of the system when you are building a compiler.","title":"Motivations"},{"location":"#examples","text":"The following outputs could be generated by code snippets in this repository.","title":"Examples"},{"location":"#three-addresses-codes","text":"Figure 1 shows how a single pass compiler can generate three address code for assignment statements with minimum numbers of temporary variable, started with T : Fig 1: Examples of three addresses codes generated by ANTLR for AssignmentStatement grammar.","title":"Three addresses codes"},{"location":"#abstract-syntax-tree-ast","text":"Figure 2 demonstrates how a single pass compiler can generate abstract syntax three (AST) for assignment statements. Fig 2: Examples of abstract syntax tree (AST) generated by ANTLR for AssignmentStatement grammar.","title":"Abstract Syntax Tree (AST)"},{"location":"#structure","text":"The following describes the structure of the repository:","title":"Structure"},{"location":"#grammars","text":"gram1 : ANTRL hello world grammar. Expr1 : Simple grammar for handling mathematical expressions without any attribute and action. Expr2 : Simple attributed grammar for handling mathematical expressions with code() attribute. Expr3 : Currently, it is the same Expr2 grammar. AssignmentStatement1.g4 : The grammar to handle multiple assignment statements and mathematical expressions in programming languages like Pascal and C/C++ . AssignmentStatement2.g4 : It is the same AssignmentStatement1.g4 grammar plus attributes for code and type of rules. AssignmentStatement3.g4 : The grammar to handle multiple assignment statements and mathematical expressions in programming languages like Pascal and C/C++ . It provides semantic rules to perform type checking and semantic routines to generate intermediate representation. AssignmentStatement4.g4 : The grammar to handle multiple assignment statements and mathematical expressions in programming languages like Pascal and C/C++ . It provides semantic rules to perform type checking and semantic routines to generate intermediate representation. It has been implemented to generate intermediate representation (three addresses codes) with minimum number of \"temp\" variables. CPP14_v2 : ANTLR grammar for C++14 forked from the official ANTRL website. Some bugs have been fixed and also the rule identifiers have been added to the grammar rules. EMail.g4 : Lexical grammar to validate email addresses. EMail2.g4 : Lexical grammar to validate email addresses, fixing bugs in EMail.g4","title":"grammars"},{"location":"#language_apps","text":"The language_apps package currently contains Lexer and Parser codes for each grammar in directory grammars , with a main driver script to demonstrate the type checking and intermediate code generation based on semantic rules and semantic routines .","title":"language_apps"},{"location":"#terminal_batch_scripts","text":"The termina_batch_script directory contains several batch script to run ANTLR in terminal (Windows) to generate target code in JAVA language. The code snippets in this directory belong to my first experiences with ANTLR.","title":"terminal_batch_scripts"},{"location":"#read-more","text":"IUST compiler course official webpage ANTLR slides: PART 1: Introduction ANTLR slides: PART 2: Getting started in Java ANTLR slides: PART 3: Getting started in C#","title":"Read more"},{"location":"antlr_tutorials/antlr_advanced/","text":"ANTLR advanced tutorials To be announced.","title":"Advanced"},{"location":"antlr_tutorials/antlr_advanced/#antlr-advanced-tutorials","text":"To be announced.","title":"ANTLR advanced tutorials"},{"location":"antlr_tutorials/antlr_basics/","text":"ANTLR basic tutorials Introduction to ANTLR: Part I Antlr part1 introduction from Morteza Zakeri Introduction to ANTLR: Part II Antlr part2 getting_started_in_java from Morteza Zakeri Introduction to ANTLR: Part III Antlr part3 getting_started_in_c_sharp from Morteza Zakeri","title":"Basic"},{"location":"antlr_tutorials/antlr_basics/#antlr-basic-tutorials","text":"","title":"ANTLR basic tutorials"},{"location":"antlr_tutorials/antlr_basics/#introduction-to-antlr-part-i","text":"Antlr part1 introduction from Morteza Zakeri","title":"Introduction to ANTLR: Part I"},{"location":"antlr_tutorials/antlr_basics/#introduction-to-antlr-part-ii","text":"Antlr part2 getting_started_in_java from Morteza Zakeri","title":"Introduction to ANTLR: Part II"},{"location":"antlr_tutorials/antlr_basics/#introduction-to-antlr-part-iii","text":"Antlr part3 getting_started_in_c_sharp from Morteza Zakeri","title":"Introduction to ANTLR: Part III"},{"location":"assignments/programming_assignment/","text":"Programming assignments Current semester Archive Semester 971 Semester 962 Semester 961","title":"Programming assignments"},{"location":"assignments/programming_assignment/#programming-assignments","text":"","title":"Programming assignments"},{"location":"assignments/programming_assignment/#current-semester","text":"","title":"Current semester"},{"location":"assignments/programming_assignment/#archive","text":"","title":"Archive"},{"location":"assignments/programming_assignment/#semester-971","text":"","title":"Semester 971"},{"location":"assignments/programming_assignment/#semester-962","text":"","title":"Semester 962"},{"location":"assignments/programming_assignment/#semester-961","text":"","title":"Semester 961"},{"location":"assignments/writing_assignments/","text":"Writing assignments Current semester Archive Semester 971 HW1 HW2 HW3 (Dr. Parsa Questions) Semester 962 HW1 HW2 HW3 HW4","title":"Writing assignments"},{"location":"assignments/writing_assignments/#writing-assignments","text":"","title":"Writing assignments"},{"location":"assignments/writing_assignments/#current-semester","text":"","title":"Current semester"},{"location":"assignments/writing_assignments/#archive","text":"","title":"Archive"},{"location":"assignments/writing_assignments/#semester-971","text":"HW1 HW2 HW3 (Dr. Parsa Questions)","title":"Semester 971"},{"location":"assignments/writing_assignments/#semester-962","text":"HW1 HW2 HW3 HW4","title":"Semester 962"},{"location":"language_applications/assignment_statement1main/","text":"Assignment statement 1 Main script for grammar AssignmentStatement1 (version 1) author Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/) date 20201029 Required Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x Changelog v2.0.0 A lexer and parser for simple grammar without any attribute or listener Refs Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/ main ( args ) Create lexer and parser Parameters: Name Type Description Default args str required return None required Source code in language_apps\\assignment_statement_v1\\assignment_statement1main.py def main ( args ): \"\"\" Create lexer and parser Args: args (str): return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) # input_stream = StdinStream() # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement1Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement1Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener my_listener = MyListener () walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) quit () # return lexer . reset () token = lexer . nextToken () while token . type != Token . EOF : print ( 'Token text: ' , token . text , 'Token line: ' , token . line ) token = lexer . nextToken ()","title":"Assignment statement 1"},{"location":"language_applications/assignment_statement1main/#assignment-statement-1","text":"Main script for grammar AssignmentStatement1 (version 1)","title":"Assignment statement 1"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main--author","text":"Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/)","title":"author"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main--date","text":"20201029","title":"date"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main--required","text":"Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x","title":"Required"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main--changelog","text":"","title":"Changelog"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main--v200","text":"A lexer and parser for simple grammar without any attribute or listener","title":"v2.0.0"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main--refs","text":"Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/","title":"Refs"},{"location":"language_applications/assignment_statement1main/#language_apps.assignment_statement_v1.assignment_statement1main.main","text":"Create lexer and parser Parameters: Name Type Description Default args str required return None required Source code in language_apps\\assignment_statement_v1\\assignment_statement1main.py def main ( args ): \"\"\" Create lexer and parser Args: args (str): return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) # input_stream = StdinStream() # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement1Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement1Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener my_listener = MyListener () walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) quit () # return lexer . reset () token = lexer . nextToken () while token . type != Token . EOF : print ( 'Token text: ' , token . text , 'Token line: ' , token . line ) token = lexer . nextToken ()","title":"main()"},{"location":"language_applications/assignment_statement2main/","text":"Assignment statement 2 Main script for grammar AssignmentStatement2 (version 2) Contains attributes for holding rule type and rule intermediate representations (AST and Three-addresses codes) author Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/) date 20201029 Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x Changelog v2.1.0 Add support for AST intermediate representation using module ast_pass Change compiler_pass module to three_address_code_pass v2.0.0 Add attributes for grammar rules which are used to hold type and intermediate language_apps of rules. Refs Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/ draw ( g = None ) Draw abstract syntax tree Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def draw ( g : nx . DiGraph = None ): \"\"\" Draw abstract syntax tree Args: g (nx.DiGraph) return (None) \"\"\" pos = nx . kamada_kawai_layout ( G = g ) pos = graphviz_layout ( G = g , prog = 'dot' , # prog='circo', ) # pos = nx.bipartite_layout(G=g, nodes=g.nodes) # pos = nx.spectral_layout(G=g) # pos = hierarchy_pos(G=g,) # pos = nx.spiral_layout(G=g) # pos = nx.spiral_layout(G=g) colors = [ g [ u ][ v ][ 'color' ] for u , v in g . edges ] nx . draw ( g , with_labels = False , node_size = 500 , node_color = 'black' , edge_color = colors , pos = pos , ) edge_labels = nx . get_edge_attributes ( g , 'edge_type' ) # print('#', edge_labels) nx . draw_networkx_edge_labels ( g , pos , edge_labels = edge_labels , ) node_labels = {} for node in g . nodes (): # set the node name as the key and the label as its value node_labels [ node ] = node . value nx . draw_networkx_labels ( g , pos , node_labels , font_size = 12 , font_color = 'w' ) plt . savefig ( '../../docs/figs/ast1.png' ) plt . show () hierarchy_pos ( G , root = None , width = 1.0 , vert_gap = 0.2 , vert_loc = 0 , xcenter = 0.5 ) From Joel's answer at https://stackoverflow.com/a/29597209/2966723. Licensed under Creative Commons Attribution-Share Alike If the graph is a tree this will return the positions to plot this in a hierarchical layout. Parameters: Name Type Description Default G nx.Graph the graph (must be a tree) required root nx.Node the root node of current branch None width float horizontal space allocated for this branch - avoids overlap with other branches 1.0 vert_gap float gap between levels of hierarchy 0.2 vert_loc float vertical location of root 0 xcenter float horizontal location of root 0.5 Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def hierarchy_pos ( G , root = None , width = 1. , vert_gap = 0.2 , vert_loc = 0 , xcenter = 0.5 ): \"\"\" From Joel's answer at https://stackoverflow.com/a/29597209/2966723. Licensed under Creative Commons Attribution-Share Alike If the graph is a tree this will return the positions to plot this in a hierarchical layout. Args: G (nx.Graph): the graph (must be a tree) root (nx.Node): the root node of current branch - if the tree is directed and this is not given, the root will be found and used - if the tree is directed and this is given, then the positions will be just for the descendants of this node. - if the tree is undirected and not given, then a random choice will be used. width (float): horizontal space allocated for this branch - avoids overlap with other branches vert_gap (float): gap between levels of hierarchy vert_loc (float): vertical location of root xcenter (float): horizontal location of root \"\"\" if not nx . is_tree ( G ): raise TypeError ( 'cannot use hierarchy_pos on a graph that is not a tree' ) if root is None : if isinstance ( G , nx . DiGraph ): root = next ( iter ( nx . topological_sort ( G ))) # allows back compatibility with nx version 1.11 else : root = random . choice ( list ( G . nodes )) def _hierarchy_pos ( G , root , width = 1. , vert_gap = 0.2 , vert_loc = 0 , xcenter = 0.5 , pos = None , parent = None ): \"\"\"\" see hierarchy_pos docstring for most arguments pos: a dict saying where all nodes go if they have been assigned parent: parent of this branch. - only affects it if non-directed \"\"\" if pos is None : pos = { root : ( xcenter , vert_loc )} else : pos [ root ] = ( xcenter , vert_loc ) children = list ( G . neighbors ( root )) if not isinstance ( G , nx . DiGraph ) and parent is not None : children . remove ( parent ) if len ( children ) != 0 : dx = width / len ( children ) nextx = xcenter - width / 2 - dx / 2 for child in children : nextx += dx pos = _hierarchy_pos ( G , child , width = dx , vert_gap = vert_gap , vert_loc = vert_loc - vert_gap , xcenter = nextx , pos = pos , parent = root ) return pos return _hierarchy_pos ( G , root , width , vert_gap , vert_loc , xcenter ) main ( args ) Create lexer and parser and execute AST listener Parameters: Name Type Description Default param args required return None required Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def main ( args ): \"\"\" Create lexer and parser and execute AST listener Args: param (args): return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) print ( 'Input language_apps: \\n {0} ' . format ( stream )) print ( 'Result:' ) # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement2Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement2Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener # code_generator_listener = ThreeAddressCodeGeneratorListener() # code_generator_listener = ThreeAddressCodeGenerator2Listener() ast_generator = ASTListener () # Step 7(a): Walk parse tree with a customized listener (Automatically) walker = ParseTreeWalker () # walker.walk(t=parse_tree, listener=code_generator_listener) walker . walk ( t = parse_tree , listener = ast_generator ) # print_tree(node=ast_generator.ast.root, level=1) # print('\\nG=', ast_generator.g.edges) draw ( g = ast_generator . g )","title":"Assignment statement 2"},{"location":"language_applications/assignment_statement2main/#assignment-statement-2","text":"Main script for grammar AssignmentStatement2 (version 2) Contains attributes for holding rule type and rule intermediate representations (AST and Three-addresses codes)","title":"Assignment statement 2"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--author","text":"Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/)","title":"author"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--date","text":"20201029 Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x","title":"date"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--changelog","text":"","title":"Changelog"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--v210","text":"Add support for AST intermediate representation using module ast_pass Change compiler_pass module to three_address_code_pass","title":"v2.1.0"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--v200","text":"Add attributes for grammar rules which are used to hold type and intermediate language_apps of rules.","title":"v2.0.0"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main--refs","text":"Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/","title":"Refs"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main.draw","text":"Draw abstract syntax tree Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def draw ( g : nx . DiGraph = None ): \"\"\" Draw abstract syntax tree Args: g (nx.DiGraph) return (None) \"\"\" pos = nx . kamada_kawai_layout ( G = g ) pos = graphviz_layout ( G = g , prog = 'dot' , # prog='circo', ) # pos = nx.bipartite_layout(G=g, nodes=g.nodes) # pos = nx.spectral_layout(G=g) # pos = hierarchy_pos(G=g,) # pos = nx.spiral_layout(G=g) # pos = nx.spiral_layout(G=g) colors = [ g [ u ][ v ][ 'color' ] for u , v in g . edges ] nx . draw ( g , with_labels = False , node_size = 500 , node_color = 'black' , edge_color = colors , pos = pos , ) edge_labels = nx . get_edge_attributes ( g , 'edge_type' ) # print('#', edge_labels) nx . draw_networkx_edge_labels ( g , pos , edge_labels = edge_labels , ) node_labels = {} for node in g . nodes (): # set the node name as the key and the label as its value node_labels [ node ] = node . value nx . draw_networkx_labels ( g , pos , node_labels , font_size = 12 , font_color = 'w' ) plt . savefig ( '../../docs/figs/ast1.png' ) plt . show ()","title":"draw()"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main.hierarchy_pos","text":"From Joel's answer at https://stackoverflow.com/a/29597209/2966723. Licensed under Creative Commons Attribution-Share Alike If the graph is a tree this will return the positions to plot this in a hierarchical layout. Parameters: Name Type Description Default G nx.Graph the graph (must be a tree) required root nx.Node the root node of current branch None width float horizontal space allocated for this branch - avoids overlap with other branches 1.0 vert_gap float gap between levels of hierarchy 0.2 vert_loc float vertical location of root 0 xcenter float horizontal location of root 0.5 Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def hierarchy_pos ( G , root = None , width = 1. , vert_gap = 0.2 , vert_loc = 0 , xcenter = 0.5 ): \"\"\" From Joel's answer at https://stackoverflow.com/a/29597209/2966723. Licensed under Creative Commons Attribution-Share Alike If the graph is a tree this will return the positions to plot this in a hierarchical layout. Args: G (nx.Graph): the graph (must be a tree) root (nx.Node): the root node of current branch - if the tree is directed and this is not given, the root will be found and used - if the tree is directed and this is given, then the positions will be just for the descendants of this node. - if the tree is undirected and not given, then a random choice will be used. width (float): horizontal space allocated for this branch - avoids overlap with other branches vert_gap (float): gap between levels of hierarchy vert_loc (float): vertical location of root xcenter (float): horizontal location of root \"\"\" if not nx . is_tree ( G ): raise TypeError ( 'cannot use hierarchy_pos on a graph that is not a tree' ) if root is None : if isinstance ( G , nx . DiGraph ): root = next ( iter ( nx . topological_sort ( G ))) # allows back compatibility with nx version 1.11 else : root = random . choice ( list ( G . nodes )) def _hierarchy_pos ( G , root , width = 1. , vert_gap = 0.2 , vert_loc = 0 , xcenter = 0.5 , pos = None , parent = None ): \"\"\"\" see hierarchy_pos docstring for most arguments pos: a dict saying where all nodes go if they have been assigned parent: parent of this branch. - only affects it if non-directed \"\"\" if pos is None : pos = { root : ( xcenter , vert_loc )} else : pos [ root ] = ( xcenter , vert_loc ) children = list ( G . neighbors ( root )) if not isinstance ( G , nx . DiGraph ) and parent is not None : children . remove ( parent ) if len ( children ) != 0 : dx = width / len ( children ) nextx = xcenter - width / 2 - dx / 2 for child in children : nextx += dx pos = _hierarchy_pos ( G , child , width = dx , vert_gap = vert_gap , vert_loc = vert_loc - vert_gap , xcenter = nextx , pos = pos , parent = root ) return pos return _hierarchy_pos ( G , root , width , vert_gap , vert_loc , xcenter )","title":"hierarchy_pos()"},{"location":"language_applications/assignment_statement2main/#language_apps.assignment_statement_v2.assignment_statement2main.main","text":"Create lexer and parser and execute AST listener Parameters: Name Type Description Default param args required return None required Source code in language_apps\\assignment_statement_v2\\assignment_statement2main.py def main ( args ): \"\"\" Create lexer and parser and execute AST listener Args: param (args): return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) print ( 'Input language_apps: \\n {0} ' . format ( stream )) print ( 'Result:' ) # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement2Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement2Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener # code_generator_listener = ThreeAddressCodeGeneratorListener() # code_generator_listener = ThreeAddressCodeGenerator2Listener() ast_generator = ASTListener () # Step 7(a): Walk parse tree with a customized listener (Automatically) walker = ParseTreeWalker () # walker.walk(t=parse_tree, listener=code_generator_listener) walker . walk ( t = parse_tree , listener = ast_generator ) # print_tree(node=ast_generator.ast.root, level=1) # print('\\nG=', ast_generator.g.edges) draw ( g = ast_generator . g )","title":"main()"},{"location":"language_applications/assignment_statement3main/","text":"Assignment statement 3 Main script for grammar AssignmentStatement3 (version 3) Contains semantic rules to perform type checking and semantic routines to generate intermediate representation (three addresses codes) author Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/) date 20201028 Required Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x Changelog v3.0 Add semantic rules to perferm type checking Add semantic routines to generate intermediate representation (three addresses codes) Refs Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/ main ( args ) Create lexer and parser for language application Parameters: Name Type Description Default args string command line arguments required return None required Source code in language_apps\\assignment_statement_v3\\assignment_statement3main.py def main ( args ): \"\"\" Create lexer and parser for language application Args: args (string): command line arguments return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) # input_stream = StdinStream() print ( 'Input stream:' ) print ( stream ) print ( 'Compiler result:' ) # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement3Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement3Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener my_listener = MyListener () walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) quit () lexer . reset () token = lexer . nextToken () while token . type != Token . EOF : print ( 'Token text: ' , token . text , 'Token line: ' , token . line ) token = lexer . nextToken ()","title":"Assignment statement 3"},{"location":"language_applications/assignment_statement3main/#assignment-statement-3","text":"Main script for grammar AssignmentStatement3 (version 3) Contains semantic rules to perform type checking and semantic routines to generate intermediate representation (three addresses codes)","title":"Assignment statement 3"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main--author","text":"Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/)","title":"author"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main--date","text":"20201028","title":"date"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main--required","text":"Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x","title":"Required"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main--changelog","text":"","title":"Changelog"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main--v30","text":"Add semantic rules to perferm type checking Add semantic routines to generate intermediate representation (three addresses codes)","title":"v3.0"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main--refs","text":"Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/","title":"Refs"},{"location":"language_applications/assignment_statement3main/#language_apps.assignment_statement_v3.assignment_statement3main.main","text":"Create lexer and parser for language application Parameters: Name Type Description Default args string command line arguments required return None required Source code in language_apps\\assignment_statement_v3\\assignment_statement3main.py def main ( args ): \"\"\" Create lexer and parser for language application Args: args (string): command line arguments return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) # input_stream = StdinStream() print ( 'Input stream:' ) print ( stream ) print ( 'Compiler result:' ) # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement3Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement3Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener my_listener = MyListener () walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) quit () lexer . reset () token = lexer . nextToken () while token . type != Token . EOF : print ( 'Token text: ' , token . text , 'Token line: ' , token . line ) token = lexer . nextToken ()","title":"main()"},{"location":"language_applications/assignment_statement4main/","text":"Assignment statement 4 Main script for grammar AssignmentStatement4 (version 4) Contains semantic rules to perform type checking and semantic routines to generate intermediate representation (three addresses codes) Also, generates intermediate representation (three addresses codes) with minimum number of 'temp' variables author Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/) date 20201029 Required Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x Changelog v4.0 Generate intermediate representation (three addresses codes) with minimum number of 'temp' variables v3.0 Add semantic rules to perferm type checking Add semantic routines to generate intermediate representation (three addresses codes) Refs Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/ main ( args ) Create lexer and parser for language application Parameters: Name Type Description Default args string command line arguments required return None required Source code in language_apps\\assignment_statement_v4\\assignment_statement4main.py def main ( args ): \"\"\" Create lexer and parser for language application Args: args (string): command line arguments return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) # input_stream = StdinStream() print ( 'Input stream:' ) print ( stream ) print ( 'Compiler result:' ) # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement4Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement4Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener my_listener = MyListener () walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) quit () lexer . reset () token = lexer . nextToken () while token . type != Token . EOF : print ( 'Token text: ' , token . text , 'Token line: ' , token . line ) token = lexer . nextToken ()","title":"Assignment statement 4"},{"location":"language_applications/assignment_statement4main/#assignment-statement-4","text":"Main script for grammar AssignmentStatement4 (version 4) Contains semantic rules to perform type checking and semantic routines to generate intermediate representation (three addresses codes) Also, generates intermediate representation (three addresses codes) with minimum number of 'temp' variables","title":"Assignment statement 4"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--author","text":"Morteza Zakeri, (http://webpages.iust.ac.ir/morteza_zakeri/)","title":"author"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--date","text":"20201029","title":"date"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--required","text":"Compiler generator: ANTLR 4.x Target language(s): Python 3.8.x","title":"Required"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--changelog","text":"","title":"Changelog"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--v40","text":"Generate intermediate representation (three addresses codes) with minimum number of 'temp' variables","title":"v4.0"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--v30","text":"Add semantic rules to perferm type checking Add semantic routines to generate intermediate representation (three addresses codes)","title":"v3.0"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main--refs","text":"Reference: Compiler book by Dr. Saeed Parsa (http://parsa.iust.ac.ir/) Course website: http://parsa.iust.ac.ir/courses/compilers/ Laboratory website: http://reverse.iust.ac.ir/","title":"Refs"},{"location":"language_applications/assignment_statement4main/#language_apps.assignment_statement_v4.assignment_statement4main.main","text":"Create lexer and parser for language application Parameters: Name Type Description Default args string command line arguments required return None required Source code in language_apps\\assignment_statement_v4\\assignment_statement4main.py def main ( args ): \"\"\" Create lexer and parser for language application Args: args (string): command line arguments return (None): \"\"\" # Step 1: Load input source into stream stream = FileStream ( args . file , encoding = 'utf8' ) # input_stream = StdinStream() print ( 'Input stream:' ) print ( stream ) print ( 'Compiler result:' ) # Step 2: Create an instance of AssignmentStLexer lexer = AssignmentStatement4Lexer ( stream ) # Step 3: Convert the input source into a list of tokens token_stream = CommonTokenStream ( lexer ) # Step 4: Create an instance of the AssignmentStParser parser = AssignmentStatement4Parser ( token_stream ) # Step 5: Create parse tree parse_tree = parser . start () # Step 6: Create an instance of AssignmentStListener my_listener = MyListener () walker = ParseTreeWalker () walker . walk ( t = parse_tree , listener = my_listener ) quit () lexer . reset () token = lexer . nextToken () while token . type != Token . EOF : print ( 'Token text: ' , token . text , 'Token line: ' , token . line ) token = lexer . nextToken ()","title":"main()"},{"location":"language_applications/main/","text":"Main There are four language application in this repository assignment_statement_v1 assignment_statement_v2 assignment_statement_v3 assignment_statement_v4 The main module of IUST Compiler project. This module do not contains any code. Please refer to language_apps package to find classroom code snippets. Main Welcome to Compiler course This file contains the main script for all code snippets print_welcome ( name ) classmethod Print welcome message :param name: :return: Source code in iust_compilers_teaching\\main.py @classmethod def print_welcome ( cls , name ) -> None : \"\"\" Print welcome message :param name: :return: \"\"\" print ( f 'Welcome to our deragon course { name } .' )","title":"Main"},{"location":"language_applications/main/#main_1","text":"There are four language application in this repository assignment_statement_v1 assignment_statement_v2 assignment_statement_v3 assignment_statement_v4 The main module of IUST Compiler project. This module do not contains any code. Please refer to language_apps package to find classroom code snippets.","title":"Main"},{"location":"language_applications/main/#main.Main","text":"Welcome to Compiler course This file contains the main script for all code snippets","title":"Main"},{"location":"language_applications/main/#main.Main.print_welcome","text":"Print welcome message :param name: :return: Source code in iust_compilers_teaching\\main.py @classmethod def print_welcome ( cls , name ) -> None : \"\"\" Print welcome message :param name: :return: \"\"\" print ( f 'Welcome to our deragon course { name } .' )","title":"print_welcome()"},{"location":"lectures/lexical_analysis/","text":"Lexical analysis To be announced.","title":"Lexical analysis"},{"location":"lectures/lexical_analysis/#lexical-analysis","text":"To be announced.","title":"Lexical analysis"},{"location":"projects/core_clean_code_development/","text":"Core clean code development The input to our software tool, cleanCode , is a c# class. cleanCode analyzes the source code and determines how clean the code is. The output is a list of the line numbers of the given class, in which the clean code principles proposed by Robert Martin, in his book, Clean Code, are violated. The current version of cleanCode, checks 14 principles and we are going to add more principles in our next version. Click to visit clean code project .","title":"Clean code"},{"location":"projects/core_clean_code_development/#core-clean-code-development","text":"The input to our software tool, cleanCode , is a c# class. cleanCode analyzes the source code and determines how clean the code is. The output is a list of the line numbers of the given class, in which the clean code principles proposed by Robert Martin, in his book, Clean Code, are violated. The current version of cleanCode, checks 14 principles and we are going to add more principles in our next version. Click to visit clean code project .","title":"Core clean code development"},{"location":"projects/core_code_smell_development/","text":"Core code smell development The following proposal has been initially prepared for the IUST Compiler and Advanced Software Engineering courses in Winter and Spring 2021 . Note: Before reading this proposal ensure that you have read and understood the CodART white-paper . Students may form groups of up to three persons. Each group must develop mechanisms for a subset of code smells listed in Table 2 . The exact list of code smells will be assigned to each group subsequently. The refactoring operations in Table 1 and code smells in Table 2 may update during the semester. To facilitate and organized the development process, this proposal defines the project in various phases. The project is divided into three separate phases. In the first phase, students must read about refactoring and code smells and understand the current state of the CodART completely. As a practice, they are asked to fix the existing issues on the project repository about refactoring operations developed in the first proposal. In the second phase, each group is asked to develop algorithms to automatically detect one or more code smells in a given Java project using ANTLR tool and other compiler techniques. TA team frequently helps the students at this phase to develop their algorithms. In the third phase, each group is asked to connect the code smells detection scripts to the corresponding refactoring and automate the overall quality improvement process. Grading policy for BSc students Table 6 shows the grading policy for the BSc students. It may change in the future. Table 6. grading policy for BSc students Activity Score (100) Understanding the CodART project and Fix the existing issues 30 Implementing smell detection approaches 40 Connecting code smells to refactoring and harnessing the overall process 20 Documenting the new source codes and pushing them to GitHub 10 Testing project on all projects available in CodART benchmarks 20+ (extra bonus) Grading policy for MSc students Table 7 shows the grading policy for the MSc students. It may change in the future. Table 7. grading policy for MSc students Activity Score (100) Understanding the paper and presenting it 20 Implementing the paper 30 Evaluating the implementation 30 Documenting the project 20 Testing project on all projects available in CodART benchmarks 20+ (extra bonus) To follow project's future phases, meet our next proposal: Core search-based development.","title":"Code smell detection"},{"location":"projects/core_code_smell_development/#core-code-smell-development","text":"The following proposal has been initially prepared for the IUST Compiler and Advanced Software Engineering courses in Winter and Spring 2021 . Note: Before reading this proposal ensure that you have read and understood the CodART white-paper . Students may form groups of up to three persons. Each group must develop mechanisms for a subset of code smells listed in Table 2 . The exact list of code smells will be assigned to each group subsequently. The refactoring operations in Table 1 and code smells in Table 2 may update during the semester. To facilitate and organized the development process, this proposal defines the project in various phases. The project is divided into three separate phases. In the first phase, students must read about refactoring and code smells and understand the current state of the CodART completely. As a practice, they are asked to fix the existing issues on the project repository about refactoring operations developed in the first proposal. In the second phase, each group is asked to develop algorithms to automatically detect one or more code smells in a given Java project using ANTLR tool and other compiler techniques. TA team frequently helps the students at this phase to develop their algorithms. In the third phase, each group is asked to connect the code smells detection scripts to the corresponding refactoring and automate the overall quality improvement process.","title":"Core code smell development"},{"location":"projects/core_code_smell_development/#grading-policy-for-bsc-students","text":"Table 6 shows the grading policy for the BSc students. It may change in the future. Table 6. grading policy for BSc students Activity Score (100) Understanding the CodART project and Fix the existing issues 30 Implementing smell detection approaches 40 Connecting code smells to refactoring and harnessing the overall process 20 Documenting the new source codes and pushing them to GitHub 10 Testing project on all projects available in CodART benchmarks 20+ (extra bonus)","title":"Grading policy for BSc students"},{"location":"projects/core_code_smell_development/#grading-policy-for-msc-students","text":"Table 7 shows the grading policy for the MSc students. It may change in the future. Table 7. grading policy for MSc students Activity Score (100) Understanding the paper and presenting it 20 Implementing the paper 30 Evaluating the implementation 30 Documenting the project 20 Testing project on all projects available in CodART benchmarks 20+ (extra bonus) To follow project's future phases, meet our next proposal: Core search-based development.","title":"Grading policy for MSc students"},{"location":"projects/core_refactoring_to_design_patterns_development/","text":"Core refactoring to design patterns development To be announced.","title":"Refactoring to patterns"},{"location":"projects/core_refactoring_to_design_patterns_development/#core-refactoring-to-design-patterns-development","text":"To be announced.","title":"Core refactoring to design patterns development"},{"location":"projects/core_refactorings_development/","text":"Core refactoring development The following proposal was initially prepared for the IUST Compiler and Advanced compiler courses in Fall 2020. Students must form groups of up to three persons, and each group must implement several refactoring operations. The exact list of refactoring will be assigned to each group subsequently. The refactoring operations in Table 1 may update during the semester. As an example of refactoring automation, we have implemented the EncapsulateField refactoring, illustrated in Figure 1. A na\u00efve implementation is available on the project official Github page at https://m-zakeri.github.io/CodART . In addition, 26 refactoring operations in Table 1 have been implemented by MultiRefactor [7] based on RECODER , three of them have been implemented by JDeodrant [8], and other operations have been automated in [3], [6]. RECODER extracts a model of the code that can be used to analyze and modify the code before the changes are applied and written to file. The tool takes Java source code as input and will output the modified source code to a specified folder. The input must be fully compilable and must be accompanied by any necessary library files as compressed jar files. Grading policy for BSc students Table 4 shows the grading policy for the BSc students. It may change in the future. Table 4. grading policy for BSc students Activity Score (100) Refactoring operations implementation (moderate level) 50 Evaluation of the tool on the benchmark projects 30 Documentations 20 Search-based refactoring recommendation 30+ (extra bonus) Grading policy for MSc students Table 5 shows the grading policy for the MSc students. It may change in the future. Table 5. grading policy for MSc students Activity Score (100) Refactoring operations implementation (advanced level) 40 Search-based refactoring recommendation 30 Evaluation of the tool on the benchmark projects 20 Documentations 10 Improving the state-of-the-arts papers 30+ (extra bonus) To follow project's phases, refer to our next proposal: Core code smell development.","title":"Source code refactoring"},{"location":"projects/core_refactorings_development/#core-refactoring-development","text":"The following proposal was initially prepared for the IUST Compiler and Advanced compiler courses in Fall 2020. Students must form groups of up to three persons, and each group must implement several refactoring operations. The exact list of refactoring will be assigned to each group subsequently. The refactoring operations in Table 1 may update during the semester. As an example of refactoring automation, we have implemented the EncapsulateField refactoring, illustrated in Figure 1. A na\u00efve implementation is available on the project official Github page at https://m-zakeri.github.io/CodART . In addition, 26 refactoring operations in Table 1 have been implemented by MultiRefactor [7] based on RECODER , three of them have been implemented by JDeodrant [8], and other operations have been automated in [3], [6]. RECODER extracts a model of the code that can be used to analyze and modify the code before the changes are applied and written to file. The tool takes Java source code as input and will output the modified source code to a specified folder. The input must be fully compilable and must be accompanied by any necessary library files as compressed jar files.","title":"Core refactoring development"},{"location":"projects/core_refactorings_development/#grading-policy-for-bsc-students","text":"Table 4 shows the grading policy for the BSc students. It may change in the future. Table 4. grading policy for BSc students Activity Score (100) Refactoring operations implementation (moderate level) 50 Evaluation of the tool on the benchmark projects 30 Documentations 20 Search-based refactoring recommendation 30+ (extra bonus)","title":"Grading policy for BSc students"},{"location":"projects/core_refactorings_development/#grading-policy-for-msc-students","text":"Table 5 shows the grading policy for the MSc students. It may change in the future. Table 5. grading policy for MSc students Activity Score (100) Refactoring operations implementation (advanced level) 40 Search-based refactoring recommendation 30 Evaluation of the tool on the benchmark projects 20 Documentations 10 Improving the state-of-the-arts papers 30+ (extra bonus) To follow project's phases, refer to our next proposal: Core code smell development.","title":"Grading policy for MSc students"},{"location":"projects/core_source_code_instrumentation_development/","text":"Core source code instrumentation development To be announced.","title":"Source code instrumentation"},{"location":"projects/core_source_code_instrumentation_development/#core-source-code-instrumentation-development","text":"To be announced.","title":"Core source code instrumentation development"}]}